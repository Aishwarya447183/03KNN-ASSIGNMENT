{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a290e180-0a10-469d-822d-7db1e20c7618",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q1.\n",
    "\n",
    "Certainly! Here's an example of Python code that implements the K-Nearest Neighbors (KNN) classifier algorithm on the load_iris dataset from sklearn.datasets:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Input features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier on the training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "In this code, we first import the necessary modules from sklearn for loading the dataset, splitting it into training and testing sets, creating the KNN classifier, and calculating the accuracy. We then load the load_iris dataset and assign the input features to X and the target variable to y.\n",
    "\n",
    "Next, we split the dataset into training and testing sets using the train_test_split function, where 80% of the data is used for training and 20% for testing. We create a KNN classifier object with n_neighbors=3, indicating that it should consider the three nearest neighbors for classification.\n",
    "\n",
    "After that, we train the KNN classifier on the training set using the fit method. We then use the trained classifier to predict the classes for the test set with the predict method. Finally, we calculate the accuracy of the classifier by comparing the predicted classes with the actual classes and printing the result.\n",
    "\n",
    "Note that the random state is set to 42 in the train_test_split function to ensure reproducibility. Feel free to adjust the parameters and experiment with different values to see how it affects the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f349f83-e05f-4256-bd2f-5db74176ef91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q2.\n",
    "\n",
    "ertainly! Here's an example of Python code that implements the K-Nearest Neighbors (KNN) regressor algorithm on the load_boston dataset from sklearn.datasets:\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data  # Input features\n",
    "y = boston.target  # Target variable (housing prices)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN regressor with k=5\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the regressor on the training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error of the regressor\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "In this code, we first import the necessary modules from sklearn for loading the dataset, splitting it into training and testing sets, creating the KNN regressor, and calculating the mean squared error. We then load the load_boston dataset and assign the input features to X and the target variable (housing prices) to y.\n",
    "\n",
    "Next, we split the dataset into training and testing sets using the train_test_split function, where 80% of the data is used for training and 20% for testing. We create a KNN regressor object with n_neighbors=5, indicating that it should consider the five nearest neighbors for regression.\n",
    "\n",
    "After that, we train the KNN regressor on the training set using the fit method. We then use the trained regressor to predict the target variable for the test set with the predict method. Finally, we calculate the mean squared error of the regressor by comparing the predicted values with the actual values and printing the result.\n",
    "\n",
    "Note that the random state is set to 42 in the train_test_split function to ensure reproducibility. Feel free to adjust the parameters and experiment with different values to see how it affects the mean squared error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386defd8-56c0-4e64-b2da-b340e528b737",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q3.\n",
    "\n",
    "Certainly! Here's a Python code snippet that uses cross-validation to find the optimal value of K for the K-Nearest Neighbors (KNN) classifier algorithm on the load_iris dataset from sklearn.datasets\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Input features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Define the range of K values to try\n",
    "k_values = list(range(1, 21))\n",
    "\n",
    "# Perform cross-validation for each K value\n",
    "cv_scores = []\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X, y, cv=5)  # 5-fold cross-validation\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "# Find the optimal K value with the highest cross-validated score\n",
    "optimal_k = k_values[cv_scores.index(max(cv_scores))]\n",
    "print(\"Optimal K:\", optimal_k)\n",
    "\n",
    "\n",
    "In this code, we first import the necessary modules from sklearn for loading the dataset, performing cross-validation, and creating the KNN classifier. We then load the load_iris dataset and assign the input features to X and the target variable to y.\n",
    "\n",
    "Next, we define a range of K values to try, in this case, from 1 to 20. For each K value, we create a KNN classifier object and use the cross_val_score function to perform 5-fold cross-validation. The cross_val_score function splits the data into 5 folds, trains the KNN classifier on 4 folds, and evaluates its performance on the remaining fold. This process is repeated 5 times, with each fold serving as the test set once.\n",
    "\n",
    "We store the mean cross-validated scores for each K value in the cv_scores list. Finally, we find the optimal K value by selecting the one with the highest cross-validated score, and print it as the result.\n",
    "\n",
    "Note that you can adjust the range of K values and the number of folds (by modifying the cv parameter in cross_val_score) according to your needs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c4619c-263f-458e-9d42-bca7d33ae5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q4.\n",
    "\n",
    "To implement the K-Nearest Neighbors (KNN) regressor algorithm with feature scaling on the load_boston dataset from sklearn.datasets, you can use the StandardScaler class from sklearn.preprocessing to scale the input features. Here's an example of Python code:\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X = boston.data  # Input features\n",
    "y = boston.target  # Target variable (housing prices)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a KNN regressor with k=5\n",
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "\n",
    "# Train the regressor on the scaled training set\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the target variable for the scaled test set\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the mean squared error of the regressor\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "In this code, we first import the necessary modules from sklearn for loading the dataset, splitting it into training and testing sets, creating the KNN regressor, performing feature scaling, and calculating the mean squared error. We then load the load_boston dataset and assign the input features to X and the target variable (housing prices) to y.\n",
    "\n",
    "Next, we split the dataset into training and testing sets using the train_test_split function, where 80% of the data is used for training and 20% for testing. We then create a StandardScaler object and use it to perform feature scaling on the training set with the fit_transform method. We apply the same scaling transformation to the test set using the transform method.\n",
    "\n",
    "After that, we create a KNN regressor object with n_neighbors=5. We train the regressor on the scaled training set using the fit method. We then use the trained regressor to predict the target variable for the scaled test set with the predict method. Finally, we calculate the mean squared error of the regressor by comparing the predicted values with the actual values and printing the result.\n",
    "\n",
    "Using feature scaling is beneficial for KNN as it helps to normalize the input features and bring them to a similar scale, which can improve the performance of the algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed36ad7c-718c-4f48-a73e-d470cb39a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q5.\n",
    "\n",
    "To implement the K-Nearest Neighbors (KNN) classifier algorithm with weighted voting on the load_iris dataset from sklearn.datasets, you can use the KNeighborsClassifier class from sklearn.neighbors and set the weights parameter to \"distance\". This will assign weights to each neighbor based on their distance to the query point. Here's an example of Python code:\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Input features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a KNN classifier with weighted voting\n",
    "knn = KNeighborsClassifier(n_neighbors=3, weights=\"distance\")\n",
    "\n",
    "# Train the classifier on the training set\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the classes for the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "In this code, we first import the necessary modules from sklearn for loading the dataset, splitting it into training and testing sets, creating the KNN classifier, and calculating the accuracy. We then load the load_iris dataset and assign the input features to X and the target variable to y.\n",
    "\n",
    "Next, we split the dataset into training and testing sets using the train_test_split function, where 80% of the data is used for training and 20% for testing. We create a KNN classifier object with n_neighbors=3 and set the weights parameter to \"distance\", indicating that the weights for each neighbor will be inversely proportional to their distance.\n",
    "\n",
    "After that, we train the KNN classifier on the training set using the fit method. We then use the trained classifier to predict the classes for the test set with the predict method. Finally, we calculate the accuracy of the classifier by comparing the predicted classes with the actual classes and printing the result.\n",
    "\n",
    "Note that you can adjust the n_neighbors parameter and experiment with different values to see how it affects the accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b63207d-03d3-4f16-a2a3-f459b01b67c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q6.\n",
    "\n",
    "To standardize the features before applying the K-Nearest Neighbors (KNN) classifier, you can use the StandardScaler class from sklearn.preprocessing. Here's an example of a Python function that standardizes the features:\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Standardizes the features using the StandardScaler.\n",
    "\n",
    "    Parameters:\n",
    "        X_train (numpy.ndarray): Training features.\n",
    "        X_test (numpy.ndarray): Test features.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Standardized training features.\n",
    "        numpy.ndarray: Standardized test features.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "ou can use this function in conjunction with the KNN classifier to standardize the features before training and testing the classifier. Here's an example of how you can apply it to the load_iris dataset:\n",
    "\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data  # Input features\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "X_train_scaled, X_test_scaled = standardize_features(X_train, X_test)\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier on the standardized training set\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict the classes for the standardized test set\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "In this code, the standardize_features function takes the training features X_train and test features X_test as input. It creates a StandardScaler object, fits it on the training features using fit_transform, and applies the scaling transformation to both the training and test features using transform. It then returns the standardized training and test features.\n",
    "\n",
    "In the main code, after loading the load_iris dataset and splitting it into training and testing sets, the standardize_features function is called to obtain the standardized features. The KNN classifier is then created and trained on the standardized training set. Finally, the classifier is used to predict the classes for the standardized test set, and the accuracy is calculated and printed.\n",
    "\n",
    "Standardizing the features before applying the KNN classifier can be beneficial as it ensures that all features are on a similar scale, which can improve the performance of the algorithm and prevent any features from dominating the distance calculations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7bf808-e49f-4782-be0f-78ab705daaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q7.\n",
    "\n",
    "Certainly! Here's a Python function that calculates the Euclidean distance between two points:\n",
    "\n",
    "import math\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculates the Euclidean distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "        point1 (list or tuple): Coordinates of the first point.\n",
    "        point2 (list or tuple): Coordinates of the second point.\n",
    "\n",
    "    Returns:\n",
    "        float: Euclidean distance between the two points.\n",
    "    \"\"\"\n",
    "    # Ensure both points have the same dimensionality\n",
    "    assert len(point1) == len(point2), \"Points must have the same dimensionality\"\n",
    "\n",
    "    # Calculate the sum of squared differences for each dimension\n",
    "    squared_diff = sum([(p1 - p2) ** 2 for p1, p2 in zip(point1, point2)])\n",
    "\n",
    "    # Take the square root of the sum of squared differences\n",
    "    distance = math.sqrt(squared_diff)\n",
    "\n",
    "    return distance\n",
    "\n",
    "In this function, we first import the math module to use the sqrt function for taking the square root. The euclidean_distance function takes two points, point1 and point2, as input.\n",
    "\n",
    "To ensure that both points have the same dimensionality, we use an assertion statement to check if the lengths of point1 and point2 are equal. If they are not, an assertion error will be raised.\n",
    "\n",
    "Next, we calculate the squared differences between the corresponding coordinates of the two points using a list comprehension. The zip function is used to iterate over the coordinates of point1 and point2 simultaneously.\n",
    "\n",
    "We then sum up the squared differences to obtain the sum of squared differences for each dimension.\n",
    "\n",
    "Finally, we take the square root of the sum of squared differences using the math.sqrt function, and return the resulting Euclidean distance.\n",
    "\n",
    "You can use this euclidean_distance function to calculate the Euclidean distance between any two points in your code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8de217e-6024-4bc2-8633-fb8633637890",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Q8.\n",
    "\n",
    "Certainly! Here's a Python function that calculates the Manhattan distance between two points:\n",
    "\n",
    "def manhattan_distance(point1, point2):\n",
    "    \"\"\"\n",
    "    Calculates the Manhattan distance between two points.\n",
    "\n",
    "    Parameters:\n",
    "        point1 (list or tuple): Coordinates of the first point.\n",
    "        point2 (list or tuple): Coordinates of the second point.\n",
    "\n",
    "    Returns:\n",
    "        float: Manhattan distance between the two points.\n",
    "    \"\"\"\n",
    "    # Ensure both points have the same dimensionality\n",
    "    assert len(point1) == len(point2), \"Points must have the same dimensionality\"\n",
    "\n",
    "    # Calculate the sum of absolute differences for each dimension\n",
    "    abs_diff = sum([abs(p1 - p2) for p1, p2 in zip(point1, point2)])\n",
    "\n",
    "    return abs_diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
